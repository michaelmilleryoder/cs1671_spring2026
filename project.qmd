---
title: "Project"
---

*Last revised 2026-02-06.*

A major component of this course is a hands-on final project guided by students' own interests. In this project, students will demonstrate an ability to build and evaluate an NLP system that takes in language data and automatically produces some sort of output.

Projects will be done in groups of ~5 students. Groups will be formed during an in-class project match day based on interest in the same project ideas.

## Project idea form
*Due 02-05*.  

In [this form](https://forms.cloud.microsoft/r/eAqzLSk0yd), you can submit project ideas you might be interested in working on. You can fill out ideas from the example projects listed below or one of your own ideas.
For your own ideas, consider what computer system you'd like to build that processes language in some form, interesting text datasets you'd like to work on, really anything! It is best if your idea has a dataset in mind, but this is not required. 

You can fill out as many ideas as you'd like with this form. Ideas do not have to be fully sketched out. Submitting an idea does mean you will necessarily work on it. These ideas will be presented to all students **anonymously**. Each student must submit at least one idea for credit on this assignment, even if it's just chosen from the example projects.

### Example projects
Some of these projects are drawn from "shared tasks" where NLP researchers compete for the best performance on certain datasets.
The instructor will provide data for these projects, though it may still require further preprocessing for use.

#### 1. Text classification
1. Classify adversarial prompts for LLMs based on attack type, using publicly available red-teaming datasets. 
1. Given a review of a restaurant, determine what type of restaurant it is from [this Yelp dataset](https://business.yelp.com/data/resources/open-dataset/)
1.  Given a short essay in response to a troubling news article, predict the level of empathy. See [WASSA 2024 shared task Track 3](https://codalab.lisn.upsaclay.fr/competitions/18810).
2.  Predict emotion labels from tweets across many languages. See [WASSA 2024 shared task](https://codalab.lisn.upsaclay.fr/competitions/17730#learn_the_details)
3. Given a news article and a list of "entities" (people, organizations, etc), predict roles such as *protagonist*, *antagonist*, and *innocent*. See [SemEval 2025 Task 10, Subtask 1 on entity framing](https://propaganda.math.unipd.it/semeval2025task10/)
4.  Predict news genre or media "frames" such as *morality*, *economic*, or *crime and punishment* from news articles in multiple languages. See [SemEval 2023 Task 3, Subtasks 1 or 2](https://propaganda.math.unipd.it/semeval2023task3/)
5. Predict whether text was written by humans or generated by AI. Tasks include predicting for data across languages and for academic essays. See [GenAI Content Detection Workshop, Task 1 or 2](https://genai-content-detection.gitlab.io/sharedtasks)
6. Classify tweets as sexist or not, or predict the "intent" of sexist tweets as *direct*, *reported* or *judgemental*. See [EXIST 2024 Task 1 or Task 2](https://nlp.uned.es/exist2024/)
7. Predict if similar words are redundant or not with the [Semantic Pleonasm corpus](https://pleonasm.cs.pitt.edu/#) developed right here at Pitt.

#### 2. Machine translation
1. Train translation models for literary text and evaluate on a dataset of Korean-English webnovels developed by a former student in this class.
1. Translate customer service chats in between languages. See the [WMT 2024 Chat Shared Task](https://wmt-chat-task.github.io/2024/)
2. Translate code-mixed Hinglish to English. See the [WMT 2022 Code-mixed Machine Translation Task](https://www.statmt.org/wmt22/code-mixed-translation-task.html)
3. Create a system to automatically correct (post-edit) machine translations. See the [WMT 2022 Automatic Post-Editing Shared Task](https://www.statmt.org/wmt22/ape-task.html)

#### 3. Information retrieval and extraction
1. Given a query, retrieve the most relevant passages from regulatory documents: <https://www.codabench.org/competitions/3527/>
2. Extract important entities from scientific articles with the [SCIRex dataset](https://github.com/allenai/SciREX?tab=readme-ov-file)

#### 4. Summarization
1. Automatically summarize movies based on their subtitles from this [dataset](https://github.com/VeerabadraLokesh/moviesubsummarize) developed by former students in the class.

#### 5. Analysis and annotation of datasets
1. Improve part-of-speech tagging and other linguistic annotation for spontaneous speech in the [Archive of Pittsburgh Language and Speech (APLS)](https://apls.pitt.edu/) with collaborator Prof. Dan Villarreal in the Linguistics Department. An evaluation dataset for parts of speech has already been manually annotated and so this project is ready to go to evaluate different systems! This work would help linguistics researchers study specific linguistic phenomena by speakers here in Pittsburgh.
1. Visualize similarities in US state legislature bill texts and predict bill passage using data from LegiScan (example repo [here](https://github.com/MaanyaShanker/Omnibus-Dissection/tree/main/data)).
1. Develop an annotation guide and start annotating a new dataset of online gaming voice chat for hate speech, abusive, and offensive language.
1. Hate speech is culturally specific, yet the majority of NLP work focuses on English in North American and European contexts. A quantitative analysis of different features of datasets annotated for hate speech in multiple languages and from multiple cultural contexts would illuminate global similarities and culturally specific contexts.
<!--1. Fanfiction, online writing by fans of media works, is known for celebrating queer identity but still may center the experiences of white authors and characters. Use FanfictionNLP to compare representations of characters of color to white characters in fanfiction at scale.-->
1. Quantitative analysis of hateful, white supremacist narratives usually centers on contemporary online discourse. Yet many white supremacist language and narratives has its roots before online discourse. Compare narratives, topics and themes presented in historic and contemporary white supremacist discourse with data provided by the instructor.
1. Explore similarities and differences between language in podcasts and Reddit communities based on those podcasts using a [dataset](https://github.com/FishOfPitt116/CS2731Project/tree/main) assembled by former Pitt students.
1. Computational analysis of Palestinian Nakba narratives. See [workshop](https://sina.birzeit.edu/nakba-nlp/) and [datasets](https://t.ly/00Ul6).
1. Examine the framing of different entities in police Facebook posts from the [Plain View Project](https://www.plainviewproject.org/).
1. Analyze how different newspapers cover topics differently in English-language editorials from Sri Lankan newspapers. Data is provided by the instructor and a collaborator at Carnegie Mellon University.


## Project group match day
*In class 02-11*.  
Students will form groups of ~5 people around 
<!--a list of submitted project ideas.-->
the following list of potential projects
Note that this list of project ideas is much greater than the final number of groups will be, so not all project ideas will have groups. Come to match day with multiple project options!

### Project idea list

1. Automatically summarize movies based on their subtitles from this [dataset](https://github.com/VeerabadraLokesh/moviesubsummarize) developed by former students in the graduate NLP class here at Pitt. *This project is the same as project 4.1 in the example projects list above.*
1. Given a review of a restaurant, determine what type of restaurant it is from [this Yelp dataset](https://business.yelp.com/data/resources/open-dataset/). *This project is the same as project 1.2 in the example projects list above.*
1. Predict whether text was written by humans or generated by AI. Tasks include predicting for data across languages and for academic essays. See [GenAI Content Detection Workshop, Task 1 or 2](https://genai-content-detection.gitlab.io/sharedtasks) and [dataset](https://github.com/mbzuai-nlp/COLING-2025-Workshop-on-MGT-Detection-Task1/tree/main?tab=readme-ov-file#dataset). *This project is the same as project 1.7 in the example projects list above.*
1. Train translation models for literary text and evaluate on a dataset of Korean-English webnovels developed by a former student in this class. *This project is the same as project 2.1 in the example projects list above.*
1. Translate customer service chats in between languages. See the [WMT 2024 Chat Shared Task](https://wmt-chat-task.github.io/2024/). *This project is the same as project 2.2 in the example projects list above.*
3. Create a system to automatically correct (post-edit) machine translations. See the [WMT 2022 Automatic Post-Editing Shared Task](https://www.statmt.org/wmt22/ape-task.html). *This project is the same as project 2.4 in the example projects list above.*
6. Classify tweets as sexist or not, or predict the "intent" of sexist tweets as *direct*, *reported* or *judgemental*. See [EXIST 2024 Task 1 or Task 2](https://nlp.uned.es/exist2024/). *This project is the same as project 1.8 in the example projects list above.*
1. Develop an annotation guide and start annotating a new dataset of online gaming voice chat for hate speech, abusive, and offensive language. *This project is the same as project 5.3 in the example projects list above.*
1. Improve part-of-speech tagging and other linguistic annotation for spontaneous speech in the [Archive of Pittsburgh Language and Speech (APLS)](https://apls.pitt.edu/) with collaborator Prof. Dan Villarreal in the Linguistics Department, with data already available to evaluate systems. This work would help linguistics researchers study specific linguistic phenomena by speakers here in Pittsburgh. *This project is the same as project 5.1 in the example projects list above.*
1. Predict stock price change or other market behavior from public datasets of financial news ([like this one](https://www.kaggle.com/datasets/jeet2016/us-financial-news-articles)) or Reddit forums.
1. Track language change in TV show characters over time, such as with Mitchell Pritchett and Cameron Tucker, the two gay characters in *Modern Family*, with quantitative approaches to supplement an existing qualitative linguistic analysis.
1. Pre-train and post-train LLMs from scratch, potentially comparing performance on specific tasks or datasets of interest.
1. Summarize Electronic Health Reports (EHRs).
1. Extract and categorize sentiment from students learning quantum information science (as part of an existing research project).
1. Classify where formal or informal *you* is used across Romance languages with a T-V distinction (tu-vous, t√∫-usted, etc) in order to surface context clues for appropriate choice of formality.
1. Build a speech-to-speech live translator using data such as [CVSS](https://github.com/google-research-datasets/cvss), or build models to identify what language is being spoken from speech data.
1. Predict genre or artist from song lyrics, or surface emotional cues and sentiment in song lyrics across genres.
1. Predict whether posts came from Moltbook or Reddit.
1. Evaluate "distilling" intelligence of large, high-performance models into smaller models and quantify the reduction in computational cost.


## Project proposal
*Due 02-27*.  
Please submit one per group on Canvas. There is no required length or format for this report. This proposal will be a report with answers to a series of questions. It will include a peer review where you will rate your own performance and the performance of other group members through 
a form.
<!--the form [here](https://forms.office.com/r/T81fQeLfay).-->

1. **Task**: What is the problem or task you are focusing on?
1. **Input and output**: What is the format of the input and output of this task? For example, each input could be a sentence of text and the output could be a label from a discrete set of possible labels. Provide at least one example of input and output from your data (ideally actual input and output, but it's fine if they are made up).
1. **Data**: What data are you using? 
	1. How many rows (datapoints) are in the dataset and what does each datapoint correspond to? 
	2. How many columns are in the dataset and what does each correspond to?  
	1. If applicable, the distribution of the target labels you are predicting. So for a binary sentiment classification task, how many rows in each set (except the test set) are marked negative or positive sentiment? This can be in a table or graph format.
	3. Provide a very small subset of the data in a table. 
	4. Please explain where the dataset came from and how it was constructed, if known. 
	5. Provide links to any URLs if the data is hosted online or links to papers if the dataset is published somewhere. 
	6. If the data has annotated labels or "gold" text that you are predicting or generating, where do those labels come from?
1. **Methods**: What approach are you taking to building a NLP system to handle this task? What models and if appropriate, what methods of extracting features from text will be used?  What software packages are you planning to use to build this system? Except in some cases, the approach should draw on statistical approaches we've covered in class so far, such as n-gram representations of text. After we directly cover LLMs in this course, you will propose additional project methods using LLMs. Talk to the instructor if you are not sure about this.
1. **Evaluation**: How are you evaluating your approach? What performance metrics are you going to use?
1. **Ethics**: What kinds of ethical issues may be raised by your model or data?
1. **Steps**: What are the proposed steps needed for completion of (your proposed part) of the project? This should be in some detail, for example, loading and potentially cleaning the data, training models, trying different parameters, evaluating models, etc.
1. **Roles**: What are roles and tasks of each person in the group? Though group members will contribute in various capacities, it is best if each person is responsible for at least one aspect of the project.

## Project proposal presentation 
*In class 03-04*.  
Groups will make a brief presentation to the class outlining their proposed project, with Q&A and opportunities for feedback from other students. Please plan for maximum **5-minute** presentations not including Q&A, which will be held right afterward for each group. 
A shared PowerPoint presentation will be provided for you to add your slides to.
<!--Please add your slides to this [shared PowerPoint presentation](https://pitt-my.sharepoint.com/:p:/g/personal/mmyoder_pitt_edu/EeSMJg2bTTRPowVW_nEg_KoBJ2FEDwcwF5miQ-WuAi5QsA?e=OigMxy).-->
Presentations are not graded. Cover at least these key points:

1. Project motivation
1. What data you are planning to use
1. What approach/methods you plan to take
1. How you will evaluate your approach

## Progress report
*Due 03-26*.  

The progress report will contain a substantive update on your group's progress using traditional (usually n-gram based) approaches on your task, as well as a description of how you will use LLMs for your task. Please provide a specification of your problem/task and input and output. You do not have to repeat information from the project proposal except for that basic description of the project. Here are the details:

### Part 1: Basic data analysis
In this part, please provide the following information about your dataset. It's fine to be working with multiple datasets; just complete this for each one or for a final dataset you will be using if you are combining datasets.

1. If it has been updated from the proposal, provide the number of rows (datapoints) and columns in the dataset and what each datapoint and column corresponds to. If you are splitting the dataset into a training, test, and possible dev sets, how many rows are in each?
1. Optionally, any other distribution or data visualization that you think is helpful for understanding your dataset or task.

### Part 2: A result from baseline (traditional) approach
In your proposal, you described an initial baseline approach to your task, which for most groups was using n-gram features in some way. Please provide one (hopefully quantitative) result from your work so far in this direction. Ideally this would be a performance metric result from your baseline approach on a dev or test set. But if you're not that far yet, you can also provide an example of working input and output from your system or part of a system, some sort of plot or other output. You can be up front about challenges you are facing for which you might need help; to get a good grade, I'll just be looking for some sort of output from a working system or part of a system. If you are confused what this means for your project, contact the instructor.

### Part 3: LLM proposal
In the project, you will be comparing your baseline system's performance to that of an LLM. Please describe how you might use an LLM programmatically to attempt your task. The simplest way to do this would be in a "zero-shot" setting where you simply ask the LLM to do the task, but even that requires setting up and passing your data to the LLM and evaluating it. Please describe what you plan to do and which LLM you plan on using. You can also propose using more advanced approaches such as in-context learning (few-shot prompting), chain-of-thought prompting, prompt optimization or fine-tuning. Not all groups have to use an LLM here if you have already talked to the instructor; in that case, please describe the rest of the approach you will be taking to complete the project.

### Part 4: Open questions and challenges
Please describe any open questions or challenges your group has at this point. Will you need any resources other than the ones provided in class (OpenAI API access, CRCD access) or have any other questions? Also describe if the roles for each of your team members have changed since the proposal and if so, what the new roles are.

### Deliverable
Assemble your results and writing for each part in a document to submit as a PDF on Canvas. There is no required format for this document other than being in PDF format.

## Final report 
*Due 04-28*.  
At the end of the course, groups will provide a written report of their project. This project includes a quantitative comparison between at least two NLP systems on a clearly specified task or tasks. One of these is generally a more traditional NLP approach and the other involves LLMs, though your group's project may vary if you have discussed this with the instructor.

This report will be in the ACL format found [here](https://github.com/acl-org/acl-style-files). Feel free to use the Word or LaTeX templates (which is also available as an Overleaf template). The report should be a maximum of 8 pages, not including limitations, ethics, group member task breakdown, references sections or appendices. Feel free to include content from the project proposal and progress report. There is flexibility in section names, but please provide information about the following aspects of the project:

1. Abstract: a brief overview of your entire project, including what approaches you took on which datasets and any findings.
2. Introduction: should include motivation for the project and more detail on the approaches you take and your final results.
3. Data: should include the final number of datapoints and columns in the data (can be copied from the proposal)
4. Methods. Please clearly specify which techniques are novel/your own versus methods directly or indirectly from prior work (which is also fine). For LLM approaches, provide what exact prompt template was used for LLM approaches (in an appendix if needed for space), how examples were selected for few-shot prompting if used, as well as exact LLM model names.
5. Results: Include examples of input and output (predicted output from your system as well as the correct "gold" output, if applicable).
6. Discussion: Please discuss the significance of the results that you see and any other comments about what these results indicate to you. Provide an analysis of common errors from different systems.
9. Future work. This is a good place to describe things you thought about but never had time to complete!
7. Limitations (doesn't count toward page limit)
8. Ethical issues (doesn't count toward page limit)
10. Group member task breakdown (doesn't count toward page limit). This section details the high-level tasks that each group member completed.
11. References (doesn't count toward page limit). If you are able to, please fill in full references instead of just URLs. The references can use any format.
12. Appendices (optional, doesn't count toward page limit). Additional figures or explanation in one or more appendices is allowed, but they will not necessarily be considered in grading. 

A rubric used in grading will be provided.
<!--Here is the rubric that will be used in grading:

|Rubric category | Points|
|-------------------|-:|
|Clear motivation for the work is provided | 4|
|Task definition and format of the input and output is clear | 9|
|Applicable dataset/s are chosen and preprocessed | 10|
|Baseline system is properly designed and implemented | 15|
|LLM-based system is properly designed and implemented | 15|
|Results from a comparison between systems are provided | 20|
|Discussion is provided of the results and implications | 10|
|Potential future work is discussed | 4|
|Limitations of your approach or dataset are sufficiently discussed | 4|
|Ethical issues that may be raised by your system or dataset are sufficiently discussed | 4|
|Group member task breakdown is provided | 4|
|***Project content total*** | ***95***|
|Meets all formatting requirements. Is maximum 8 pages, not including limitations, ethics, references or group member task breakdown | 7|
|Writing is clear | 8|
|***Writing total*** | ***15***|
|Group member had a sufficient amount of workload in the project | 15|
|Task and roles assigned to this group member were completed sufficiently | 15|
|***Individual contribution total*** | ***30***|
|***Grand total*** | ***140***|
-->


## Final presentation
*In class TBD*.  
Groups will present their finished work to the group, with Q&A and feedback opportunities from students. Please prepare a maximum 7-minute presentation. 
A shared PowerPoint presentation will be provided to add your group's slides to.
<!--Add your slides to this [shared PowerPoint presentation](https://pitt-my.sharepoint.com/:p:/g/personal/mmyoder_pitt_edu/EdWBs5h0nvRDrqPWUMMPCzgB4c3HkyySL47wUw1DY0y2bw?e=T0kmWQ).-->
Cover at least these key points:

1. Project motivation (briefly)
1. Task description, including example input and output
2. Data
3. Methods, including your baseline system and your contemporary LLM-based approach (or whatever approaches you took)
4. Results or findings from your baseline system and your contemporary LLM-based approach
