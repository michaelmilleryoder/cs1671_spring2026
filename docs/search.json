[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Last revised 2026-02-06.\nA major component of this course is a hands-on final project guided by students’ own interests. In this project, students will demonstrate an ability to build and evaluate an NLP system that takes in language data and automatically produces some sort of output.\nProjects will be done in groups of ~5 students. Groups will be formed during an in-class project match day based on interest in the same project ideas."
  },
  {
    "objectID": "project.html#project-idea-form",
    "href": "project.html#project-idea-form",
    "title": "Project",
    "section": "Project idea form",
    "text": "Project idea form\nDue 02-05.\nIn this form, you can submit project ideas you might be interested in working on. You can fill out ideas from the example projects listed below or one of your own ideas. For your own ideas, consider what computer system you’d like to build that processes language in some form, interesting text datasets you’d like to work on, really anything! It is best if your idea has a dataset in mind, but this is not required.\nYou can fill out as many ideas as you’d like with this form. Ideas do not have to be fully sketched out. Submitting an idea does mean you will necessarily work on it. These ideas will be presented to all students anonymously. Each student must submit at least one idea for credit on this assignment, even if it’s just chosen from the example projects.\n\nExample projects\nSome of these projects are drawn from “shared tasks” where NLP researchers compete for the best performance on certain datasets. The instructor will provide data for these projects, though it may still require further preprocessing for use.\n\n1. Text classification\n\nClassify adversarial prompts for LLMs based on attack type, using publicly available red-teaming datasets.\nGiven a review of a restaurant, determine what type of restaurant it is from this Yelp dataset\nGiven a short essay in response to a troubling news article, predict the level of empathy. See WASSA 2024 shared task Track 3.\nPredict emotion labels from tweets across many languages. See WASSA 2024 shared task\nGiven a news article and a list of “entities” (people, organizations, etc), predict roles such as protagonist, antagonist, and innocent. See SemEval 2025 Task 10, Subtask 1 on entity framing\nPredict news genre or media “frames” such as morality, economic, or crime and punishment from news articles in multiple languages. See SemEval 2023 Task 3, Subtasks 1 or 2\nPredict whether text was written by humans or generated by AI. Tasks include predicting for data across languages and for academic essays. See GenAI Content Detection Workshop, Task 1 or 2\nClassify tweets as sexist or not, or predict the “intent” of sexist tweets as direct, reported or judgemental. See EXIST 2024 Task 1 or Task 2\nPredict if similar words are redundant or not with the Semantic Pleonasm corpus developed right here at Pitt.\n\n\n\n2. Machine translation\n\nTrain translation models for literary text and evaluate on a dataset of Korean-English webnovels developed by a former student in this class.\nTranslate customer service chats in between languages. See the WMT 2024 Chat Shared Task\nTranslate code-mixed Hinglish to English. See the WMT 2022 Code-mixed Machine Translation Task\nCreate a system to automatically correct (post-edit) machine translations. See the WMT 2022 Automatic Post-Editing Shared Task\n\n\n\n3. Information retrieval and extraction\n\nGiven a query, retrieve the most relevant passages from regulatory documents: https://www.codabench.org/competitions/3527/\nExtract important entities from scientific articles with the SCIRex dataset\n\n\n\n4. Summarization\n\nAutomatically summarize movies based on their subtitles from this dataset developed by former students in the class.\n\n\n\n5. Analysis and annotation of datasets\n\nImprove part-of-speech tagging and other linguistic annotation for spontaneous speech in the Archive of Pittsburgh Language and Speech (APLS) with collaborator Prof. Dan Villarreal in the Linguistics Department. An evaluation dataset for parts of speech has already been manually annotated and so this project is ready to go to evaluate different systems! This work would help linguistics researchers study specific linguistic phenomena by speakers here in Pittsburgh.\nVisualize similarities in US state legislature bill texts and predict bill passage using data from LegiScan (example repo here).\nDevelop an annotation guide and start annotating a new dataset of online gaming voice chat for hate speech, abusive, and offensive language.\nHate speech is culturally specific, yet the majority of NLP work focuses on English in North American and European contexts. A quantitative analysis of different features of datasets annotated for hate speech in multiple languages and from multiple cultural contexts would illuminate global similarities and culturally specific contexts. \nQuantitative analysis of hateful, white supremacist narratives usually centers on contemporary online discourse. Yet many white supremacist language and narratives has its roots before online discourse. Compare narratives, topics and themes presented in historic and contemporary white supremacist discourse with data provided by the instructor.\nExplore similarities and differences between language in podcasts and Reddit communities based on those podcasts using a dataset assembled by former Pitt students.\nComputational analysis of Palestinian Nakba narratives. See workshop and datasets.\nExamine the framing of different entities in police Facebook posts from the Plain View Project.\nAnalyze how different newspapers cover topics differently in English-language editorials from Sri Lankan newspapers. Data is provided by the instructor and a collaborator at Carnegie Mellon University."
  },
  {
    "objectID": "project.html#project-group-match-day",
    "href": "project.html#project-group-match-day",
    "title": "Project",
    "section": "Project group match day",
    "text": "Project group match day\nIn class 02-11.\nStudents will form groups of ~5 people around  the following list of potential projects Note that this list of project ideas is much greater than the final number of groups will be, so not all project ideas will have groups. Come to match day with multiple project options!\n\nProject idea list\n\nAutomatically summarize movies based on their subtitles from this dataset developed by former students in the graduate NLP class here at Pitt. This project is the same as project 4.1 in the example projects list above.\nGiven a review of a restaurant, determine what type of restaurant it is from this Yelp dataset. This project is the same as project 1.2 in the example projects list above.\nPredict whether text was written by humans or generated by AI. Tasks include predicting for data across languages and for academic essays. See GenAI Content Detection Workshop, Task 1 or 2 and dataset. This project is the same as project 1.7 in the example projects list above.\nTrain translation models for literary text and evaluate on a dataset of Korean-English webnovels developed by a former student in this class. This project is the same as project 2.1 in the example projects list above.\nTranslate customer service chats in between languages. See the WMT 2024 Chat Shared Task. This project is the same as project 2.2 in the example projects list above.\nCreate a system to automatically correct (post-edit) machine translations. See the WMT 2022 Automatic Post-Editing Shared Task. This project is the same as project 2.4 in the example projects list above.\nClassify tweets as sexist or not, or predict the “intent” of sexist tweets as direct, reported or judgemental. See EXIST 2024 Task 1 or Task 2. This project is the same as project 1.8 in the example projects list above.\nDevelop an annotation guide and start annotating a new dataset of online gaming voice chat for hate speech, abusive, and offensive language. This project is the same as project 5.3 in the example projects list above.\nImprove part-of-speech tagging and other linguistic annotation for spontaneous speech in the Archive of Pittsburgh Language and Speech (APLS) with collaborator Prof. Dan Villarreal in the Linguistics Department, with data already available to evaluate systems. This work would help linguistics researchers study specific linguistic phenomena by speakers here in Pittsburgh. This project is the same as project 5.1 in the example projects list above.\nPredict stock price change or other market behavior from public datasets of financial news (like this one) or Reddit forums.\nTrack language change in TV show characters over time, such as with Mitchell Pritchett and Cameron Tucker, the two gay characters in Modern Family, with quantitative approaches to supplement an existing qualitative linguistic analysis.\nPre-train and post-train LLMs from scratch, potentially comparing performance on specific tasks or datasets of interest.\nSummarize Electronic Health Reports (EHRs).\nExtract and categorize sentiment from students learning quantum information science (as part of an existing research project).\nClassify where formal or informal you is used across Romance languages with a T-V distinction (tu-vous, tú-usted, etc) in order to surface context clues for appropriate choice of formality.\nBuild a speech-to-speech live translator using data such as CVSS, or build models to identify what language is being spoken from speech data.\nPredict genre or artist from song lyrics, or surface emotional cues and sentiment in song lyrics across genres.\nPredict whether posts came from Moltbook or Reddit.\nEvaluate “distilling” intelligence of large, high-performance models into smaller models and quantify the reduction in computational cost."
  },
  {
    "objectID": "project.html#project-proposal",
    "href": "project.html#project-proposal",
    "title": "Project",
    "section": "Project proposal",
    "text": "Project proposal\nDue 02-27.\nPlease submit one per group on Canvas. There is no required length or format for this report. This proposal will be a report with answers to a series of questions. It will include a peer review where you will rate your own performance and the performance of other group members through  the form here.\n\nTask: What is the problem or task you are focusing on?\nInput and output: What is the format of the input and output of this task? For example, each input could be a sentence of text and the output could be a label from a discrete set of possible labels. Provide at least one example of input and output from your data (ideally actual input and output, but it’s fine if they are made up).\nData: What data are you using?\n\nHow many rows (datapoints) are in the dataset and what does each datapoint correspond to?\nHow many columns are in the dataset and what does each correspond to?\n\nIf applicable, the distribution of the target labels you are predicting. So for a binary sentiment classification task, how many rows in each set (except the test set) are marked negative or positive sentiment? This can be in a table or graph format.\nProvide a very small subset of the data in a table.\nPlease explain where the dataset came from and how it was constructed, if known.\nProvide links to any URLs if the data is hosted online or links to papers if the dataset is published somewhere.\nIf the data has annotated labels or “gold” text that you are predicting or generating, where do those labels come from?\n\nMethods: What approach are you taking to building a NLP system to handle this task? What models and if appropriate, what methods of extracting features from text will be used? What software packages are you planning to use to build this system? Except in some cases, the approach should draw on statistical approaches we’ve covered in class so far, such as n-gram representations of text. After we directly cover LLMs in this course, you will propose additional project methods using LLMs. Talk to the instructor if you are not sure about this.\nEvaluation: How are you evaluating your approach? What performance metrics are you going to use?\nEthics: What kinds of ethical issues may be raised by your model or data?\nSteps: What are the proposed steps needed for completion of (your proposed part) of the project? This should be in some detail, for example, loading and potentially cleaning the data, training models, trying different parameters, evaluating models, etc.\nRoles: What are roles and tasks of each person in the group? Though group members will contribute in various capacities, it is best if each person is responsible for at least one aspect of the project."
  },
  {
    "objectID": "project.html#project-proposal-presentation",
    "href": "project.html#project-proposal-presentation",
    "title": "Project",
    "section": "Project proposal presentation",
    "text": "Project proposal presentation\nIn class 03-04.\nGroups will make a brief presentation to the class outlining their proposed project, with Q&A and opportunities for feedback from other students. Please plan for maximum 5-minute presentations not including Q&A, which will be held right afterward for each group. A shared PowerPoint presentation will be provided for you to add your slides to.  Presentations are not graded. Cover at least these key points:\n\nProject motivation\nWhat data you are planning to use\nWhat approach/methods you plan to take\nHow you will evaluate your approach"
  },
  {
    "objectID": "project.html#progress-report",
    "href": "project.html#progress-report",
    "title": "Project",
    "section": "Progress report",
    "text": "Progress report\nDue 03-26.\nThe progress report will contain a substantive update on your group’s progress using traditional (usually n-gram based) approaches on your task, as well as a description of how you will use LLMs for your task. Please provide a specification of your problem/task and input and output. You do not have to repeat information from the project proposal except for that basic description of the project. Here are the details:\n\nPart 1: Basic data analysis\nIn this part, please provide the following information about your dataset. It’s fine to be working with multiple datasets; just complete this for each one or for a final dataset you will be using if you are combining datasets.\n\nIf it has been updated from the proposal, provide the number of rows (datapoints) and columns in the dataset and what each datapoint and column corresponds to. If you are splitting the dataset into a training, test, and possible dev sets, how many rows are in each?\nOptionally, any other distribution or data visualization that you think is helpful for understanding your dataset or task.\n\n\n\nPart 2: A result from baseline (traditional) approach\nIn your proposal, you described an initial baseline approach to your task, which for most groups was using n-gram features in some way. Please provide one (hopefully quantitative) result from your work so far in this direction. Ideally this would be a performance metric result from your baseline approach on a dev or test set. But if you’re not that far yet, you can also provide an example of working input and output from your system or part of a system, some sort of plot or other output. You can be up front about challenges you are facing for which you might need help; to get a good grade, I’ll just be looking for some sort of output from a working system or part of a system. If you are confused what this means for your project, contact the instructor.\n\n\nPart 3: LLM proposal\nIn the project, you will be comparing your baseline system’s performance to that of an LLM. Please describe how you might use an LLM programmatically to attempt your task. The simplest way to do this would be in a “zero-shot” setting where you simply ask the LLM to do the task, but even that requires setting up and passing your data to the LLM and evaluating it. Please describe what you plan to do and which LLM you plan on using. You can also propose using more advanced approaches such as in-context learning (few-shot prompting), chain-of-thought prompting, prompt optimization or fine-tuning. Not all groups have to use an LLM here if you have already talked to the instructor; in that case, please describe the rest of the approach you will be taking to complete the project.\n\n\nPart 4: Open questions and challenges\nPlease describe any open questions or challenges your group has at this point. Will you need any resources other than the ones provided in class (OpenAI API access, CRCD access) or have any other questions? Also describe if the roles for each of your team members have changed since the proposal and if so, what the new roles are.\n\n\nDeliverable\nAssemble your results and writing for each part in a document to submit as a PDF on Canvas. There is no required format for this document other than being in PDF format."
  },
  {
    "objectID": "project.html#final-report",
    "href": "project.html#final-report",
    "title": "Project",
    "section": "Final report",
    "text": "Final report\nDue 04-28.\nAt the end of the course, groups will provide a written report of their project. This project includes a quantitative comparison between at least two NLP systems on a clearly specified task or tasks. One of these is generally a more traditional NLP approach and the other involves LLMs, though your group’s project may vary if you have discussed this with the instructor.\nThis report will be in the ACL format found here. Feel free to use the Word or LaTeX templates (which is also available as an Overleaf template). The report should be a maximum of 8 pages, not including limitations, ethics, group member task breakdown, references sections or appendices. Feel free to include content from the project proposal and progress report. There is flexibility in section names, but please provide information about the following aspects of the project:\n\nAbstract: a brief overview of your entire project, including what approaches you took on which datasets and any findings.\nIntroduction: should include motivation for the project and more detail on the approaches you take and your final results.\nData: should include the final number of datapoints and columns in the data (can be copied from the proposal)\nMethods. Please clearly specify which techniques are novel/your own versus methods directly or indirectly from prior work (which is also fine). For LLM approaches, provide what exact prompt template was used for LLM approaches (in an appendix if needed for space), how examples were selected for few-shot prompting if used, as well as exact LLM model names.\nResults: Include examples of input and output (predicted output from your system as well as the correct “gold” output, if applicable).\nDiscussion: Please discuss the significance of the results that you see and any other comments about what these results indicate to you. Provide an analysis of common errors from different systems.\nFuture work. This is a good place to describe things you thought about but never had time to complete!\nLimitations (doesn’t count toward page limit)\nEthical issues (doesn’t count toward page limit)\nGroup member task breakdown (doesn’t count toward page limit). This section details the high-level tasks that each group member completed.\nReferences (doesn’t count toward page limit). If you are able to, please fill in full references instead of just URLs. The references can use any format.\nAppendices (optional, doesn’t count toward page limit). Additional figures or explanation in one or more appendices is allowed, but they will not necessarily be considered in grading.\n\nA rubric used in grading will be provided."
  },
  {
    "objectID": "project.html#final-presentation",
    "href": "project.html#final-presentation",
    "title": "Project",
    "section": "Final presentation",
    "text": "Final presentation\nIn class TBD.\nGroups will present their finished work to the group, with Q&A and feedback opportunities from students. Please prepare a maximum 7-minute presentation. A shared PowerPoint presentation will be provided to add your group’s slides to.  Cover at least these key points:\n\nProject motivation (briefly)\nTask description, including example input and output\nData\nMethods, including your baseline system and your contemporary LLM-based approach (or whatever approaches you took)\nResults or findings from your baseline system and your contemporary LLM-based approach"
  },
  {
    "objectID": "hw2.html",
    "href": "hw2.html",
    "title": "Homework 2: Text classification",
    "section": "",
    "text": "Due 2026-03-17, 11:59pm. Instructions last updated 2026-02-20."
  },
  {
    "objectID": "hw2.html#learning-objectives",
    "href": "hw2.html#learning-objectives",
    "title": "Homework 2: Text classification",
    "section": "Learning objectives",
    "text": "Learning objectives\nAfter completing this assignment, students will be able to:\n\nImplement a text classification system using logistic regression and feature-based approaches\nEvaluate a text classification system\nIdentify informative features in a feature-based text classification system\nAnalyze errors in an NLP system"
  },
  {
    "objectID": "hw2.html#implement-a-deception-classifier",
    "href": "hw2.html#implement-a-deception-classifier",
    "title": "Homework 2: Text classification",
    "section": "Implement a deception classifier",
    "text": "Implement a deception classifier\nYou will design and implement a program to classify if a comment from a player of the Diplomacy game is truthful or not.\nYou can use any packages you want for this (scikit-learn, spaCy, NLTK, Gensim, etc., as well as code from in-class example notebooks). Any packages used, along with version numbers, should be specified in an environment.yml, requirements.txt or pyproject.toml file. The version of Python used should also be specified in your README.txt file. If you will be using a language other than Python, please let us know before submitting."
  },
  {
    "objectID": "hw2.html#dataset",
    "href": "hw2.html#dataset",
    "title": "Homework 2: Text classification",
    "section": "Dataset",
    "text": "Dataset\nHere is the dataset that you should download for this assignment:\n\ndiplomacy_train.csv. This dataset has a variety of fields, but the most important are:\n\ntext: the text of the comment\nintent: 0 for truth, 1 for lie\n\ndiplomacy_dev.csv. This is the development set to be used for evaluation and error analysis.\ndiplomacy_kaggle.csv. This data has the same fields as the training data, but does not have the “correct” intent filled in. This file is to be used as a test set for the challenge competition hosted on Kaggle.\n\nThe data is from a recording of online players of Diplomacy, as presented in Peskov et al. 2020. Negotiation and back-stabbing are key elements of the Diplomacy game."
  },
  {
    "objectID": "hw2.html#part-1-feature-based-logistic-regression-models",
    "href": "hw2.html#part-1-feature-based-logistic-regression-models",
    "title": "Homework 2: Text classification",
    "section": "Part 1: Feature-based logistic regression models",
    "text": "Part 1: Feature-based logistic regression models\nIn this section, you will build a logistic regression model based on bag-of-word features and/or features of your own design, trained on diplomacy_train.csv. You can do whatever preprocessing you see fit, but make sure to mention the preprocessing steps you took in the report. You will report performance on the diplomacy_dev.csv dataset.\nImplement and try the following feature and model combinations:\n\nLogistic regression with bag-of-words (unigram) features. Build a logistic regression classifier that uses bag-of-words (unigram) features.\nLogistic regression with your own features/change in preprocessing. Design and test at least two modifications (custom features or preprocessing changes) to unweighted unigram features. Note that these features can be used in conjunction with bag-of-words features or by themselves. Possible features/changes to add and test include:\n\nTf-idf transformed bag-of-words features. See J+M 11.1.2 for a description of tf-idf\nHigher order n-gram features (bigrams, trigrams, or combinations of them) beyond the unigrams used for the bag-of-words features\nDifferent preprocessing (stemming, different tokenizations, stopword removal)\nChanging count bag-of-words features to binary 0 or 1 for the presence of unigrams\nIncorporating features from columns in the dataset other than text\nReducing noisy features with feature selection\nCounts or added weight from custom word lists\nAny other custom-designed feature (such as length of input, number of capitalized words, neural embeddings of text, etc)\n\n\nYou will thus have 3 total logistic regression models: one using bag-of-word features and 2 with your own selected features or preprocessing changes.\n\nInclude in the report\n\n1. Preprocessing steps\nWhat preprocessing was or was not done to the text, including tokenization, lowercasing, removing stopwords or other choices. Mention any packages used for this preprocessing and even if you use default settings, explain what those settings are.\n\n\n2. Performance table\nReport a table of performance scores for models trained on each set of features, evaluated on diplomacy_dev.csv. Include accuracy as well as the following metrics for the positive (lying) class: precision, recall, and f1-score.\n\n\n3. Feature descriptions\nFor each feature or change in input text processing:\n\nDescribe your motivation for including the feature\nDiscussion of results: Did it improve performance or not? (Either result is fine. It is not necessary to beat logistic regression with unigram features.)\n\n\n\n4. Informative features and error analysis\nFor a feature-based model of your choice:\n\nExtract and discuss the most informative features that are mostly strongly positively and negatively associated with deception. Please normalize feature values to some sort of standard scale for interpretation. We did not cover this in class, so you will have to do some reading online about it (see scikit-learn’s StandardScaler class as one option). Report the 5 features with the highest weights and 5 features with the lowest (negative) weights. Discuss how these may or may not make sense for this task. You may adapt code provided by the instructor, use another source online (with a mention of the source URL), or write your own. Give specific informative features, such as particular words (e.g. “actually”) for bag-of-words features, instead of sets of features like “bigram features”.\nDo an error analysis. On the dev set, provide a confusion matrix. Sample examples from both false negatives and false positives and present a few of them in the report. Do you see any patterns in these errors? Does the list of informative features provide evidence for any of the patterns you’re seeing? How might these errors be addressed with different features or if the system could understand something else? (You don’t have to implement these, just speculate.)"
  },
  {
    "objectID": "hw2.html#part-2-submit-your-classifier-in-the-class-challenge",
    "href": "hw2.html#part-2-submit-your-classifier-in-the-class-challenge",
    "title": "Homework 2: Text classification",
    "section": "Part 2: Submit your classifier in the class challenge",
    "text": "Part 2: Submit your classifier in the class challenge\nPlease submit your classifier to run on a hidden held-out test set as part of a class competition. It is necessary to submit one of your classifiers, but you will not be graded on your performance. Instead, bonus points will be awarded for top systems. Bonus points will be awarded in the competition as follows, as measured by accuracy on our held-out test set.\n\n6 bonus points for the best-performing logistic regression classifier\n4 bonus points for the 2nd best-performing logistic regression classifier\n2 bonus points for the 3rd best-performing logistic regression classifier\n\n\nHow to submit your classifier\nThis optional competition is conducted on Kaggle. See this page for instructions on how to submit: https://www.kaggle.com/t/fa4086c7b9f0469e994075b4c4f427e3.\nYou will need to create a Kaggle account to submit. Let the instructor know if this is a barrier and we will work something out. Please provide your Kaggle username used in the competition in your report. Note that this username will be visible in a leaderboard to other challenge competition participants."
  },
  {
    "objectID": "hw2.html#notes",
    "href": "hw2.html#notes",
    "title": "Homework 2: Text classification",
    "section": "Notes",
    "text": "Notes\n\nDon’t feel like you need to write things from scratch; use as many packages as you want. Class Jupyter notebooks, Google, Stack Overflow, and NLP/ML software documentation are your friend! Adapting and consulting other approaches is fine and should be noted in comments in the code and/or in the README.txt. Just don’t use complete, fully-formed implementations, including from generative AI tools. Use all resources as aids, not as a final product, and provide source URLs or generative AI description in code comments.\nOptionally, you may incorporate any form of regularization that you like."
  },
  {
    "objectID": "hw2.html#deliverables",
    "href": "hw2.html#deliverables",
    "title": "Homework 2: Text classification",
    "section": "Deliverables",
    "text": "Deliverables\n\nYour report with results and answers to questions in Part 1, named hw2_{your pitt email id}.pdf. No need to include @pitt.edu, just use the email ID before that part. For example: report_mmyoder_hw2.pdf.\nYour code used to train models and estimate performance for Part 1 in a file named hw2_{your pitt email id}_train.py.\nYour code used for the Kaggle submission in Part 2 in a file named hw2_{your pitt email id}_kaggle.py.\nA README.txt file explaining\n\nThe Kaggle username you used to submit your predictions\nhow to run the code you used to train your models and calculate dev set performance\nthe version of Python used\nany additional files needed to run the code\nany additional resources, references, or web pages you’ve consulted\nany person with whom you’ve discussed the assignment and describe the nature of your discussions\nany generative AI tool used, and how it was used\nany unresolved issues or problems\n\nA requirements.txt file with:\n\nall Python packages and package versions in the computing environment you used in case we replicate your experiments\n\n\nPlease submit all of this material on Canvas. We will grade your report and look over your code."
  },
  {
    "objectID": "hw2.html#grading",
    "href": "hw2.html#grading",
    "title": "Homework 2: Text classification",
    "section": "Grading",
    "text": "Grading\nSee rubric on Canvas."
  },
  {
    "objectID": "hw2.html#acknowledgments",
    "href": "hw2.html#acknowledgments",
    "title": "Homework 2: Text classification",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis assignment is inspired from a homework assignment by Prof. Diane Litman. Data is from Peskov et al. 2020."
  },
  {
    "objectID": "hw1.html",
    "href": "hw1.html",
    "title": "Homework 1: Text and string processing in Python",
    "section": "",
    "text": "Due 2026-02-12, 11:59pm. Instructions last updated 2026-01-27.\nIn this first assignment, you’ll learn and practice some coding skills that will help you deal with text data for NLP. You will be reading/writing files, using regular expressions, and processing strings in Python. Use Python 3 in your code and any Python packages you like."
  },
  {
    "objectID": "hw1.html#learning-objectives",
    "href": "hw1.html#learning-objectives",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Learning objectives",
    "text": "Learning objectives\nAfter completing this assignments, you will be able to:\n\nLoad in text files into different data structures in Python\nUse regular expressions in Python to find and manipulate strings\nWrite Python code to produce basic statistics about a dataset of text\nSpecify the Python software environment you used to run a script"
  },
  {
    "objectID": "hw1.html#resources-to-download",
    "href": "hw1.html#resources-to-download",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Resources to download",
    "text": "Resources to download\n\nSkeleton code\nPlease download and add all your answers to the following Python script template file. It is a “skeleton” script where only the formatting is provided and you fill in the code for the rest of the file.\n\nhw1_skeleton.py\n\nPlease use a version of Python 3 to run your filled-out script. You do not have to run things on the CRCD JupyterHub unless you want to. You can just fill out and test your script locally on your own computer.\nWe encourage you to use a Python virtual environment to code this and future course assignments. Virtual environments are a way to isolate your code and its dependencies from the rest of the python programs and packages installed on your system. This is very helpful for ‘good science’ as we avoid any issues sharing our work with others and having packages break, and having a saved state where we know code works. Anaconda is a third-party tool to manage environments and Python packages. See slides from the session on Python for data science for some useful commands on setting up environments with Anaconda. You can also use the venv module and the pip package downloader to create and manage virtual environments in Python.\nOne of the deliverables for this assignment is to specify the packages and package versions in the Python environment you used while running your code. This is most straightforward within a virtual environment, though you can provide all the Python packages installed on your system as an alternative.\n\n\nData\nFor Part 1, you will need the following text file:\n\nspanish_test.txt\n\nFor Part 3, you will need a small dataset of wine reviews. You can download it and unpack it in a terminal as follows:\n$ wget http://computational-linguistics-class.org/homework/python-and-bash/data.tgz\n$ tar -xzvf data.tgz \n$ ls data\nstopwords.txt    wine.txt"
  },
  {
    "objectID": "hw1.html#part-1-file-inputoutput-io",
    "href": "hw1.html#part-1-file-inputoutput-io",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Part 1: File input/output (I/O)",
    "text": "Part 1: File input/output (I/O)\nGiven a file, it is important to know how to open, read, and write using Python functions: open(), read(), and write(). The read() function returns the entire contents of the file as a string. It is often useful to read each line of a file into a list. You can do this with the readlines() function, which will split on the newline character and return the lines as a list, presevering the newline character. You can also use the splitlines() function, which will remove the newline characters.\nTake some time to also read through the encoding argument for open() as that can be a source of trouble for files that aren’t being read in properly.\nHere’s some example code for reading and writing files in Python:\n# read files\nwith open('test.txt') as f:\n    contents = f.read().splitlines()\nfor s in contents:\n    print(s)\n\n# write files\nwith open('test.txt', 'w')\n    for s in ['line1', 'line2', 'line3', 'line4'] :\n        file.write(s+'\\n')\nOften we would like to associate metadata (such as a label) with lines or chunks of text in NLP. One way of doing this is by formatting the data as a table or spreadsheet (a CSV, comma-separated value, file) with the text in a column and other columns of metadata about that text.\nFill in the text_to_csv function in hw1_skeleton.py. You can use the csv module or the more powerful pandas package, particularly the read_csv and to_csv methods to handle data in CSV format. In this function, please fill out code to read in the spanish_test.txt file and produce a CSV file with the following columns:\n\nline_id: an integer ID column for each line, starting from 1 and continuing.\ntext: the text of the line, without any newline character included\ncharacter_length: the number of characters (length) of the line, including whitespace (but not the newline characters you removed from the text column). See the Python string module or pandas string functions.\n\nInclude column headers on the first line. Save this CSV file as spanish_test.csv. It will be part of your final submission."
  },
  {
    "objectID": "hw1.html#part-2-regular-expressions",
    "href": "hw1.html#part-2-regular-expressions",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Part 2: Regular expressions",
    "text": "Part 2: Regular expressions\nRegular expressions are a powerful way to process text by describing text patterns. Here are useful resources you may need:\n\nA fancy website to test your regex.\nPython re package that provides many regular expression functions for use.\nChapter 2 of the textbook\n\n# match patterns in given string\nimport re\npattern = 'pitt'\ntest_string = 'pittsburgh'\nresult = re.match(pattern, test_string)\nif result:\n    print(\"Search successful.\")\nelse:\n    print(\"Search unsuccessful.\") \nIn this part, you need to fill in the functions check_for_foo_or_bar and replace_rgb in the skeleton script.\n2.1. Check whether the input string meets the following condition. Useful documentation: Python match objects\n\nThe string must have both the word foo and the word bar in it, whitespace- or punctuation-delimited from other words. (not, e.g., words like foobar or bart that merely contain the word bar). You only need to match lowercase foo and bar, though it is okay if you also match any capitalized letters within foo or bar (either is acceptable).\nReturn True if the condition is met, false otherwise.\n\n2.2. Replace all RGB or hex colors with the word COLOR. Useful documentation: Python regular expression substitutions. It is fine to run multiple regular expressions substitutions if you like.\n\nPossible example formats for a color string: #0f0, #0b013a, #37EfaA, rgb(1, 1, 1), rgb(255, 19, 32), rgb(00, 001, 18.0), or rgb(0.1, 0.5, 1.0).\nNote that there is no need to try other formats that are not listed above. There is also no need to validate the ranges of the rgb values.\nHowever, you should make sure all numbers are indeed valid numbers. For example, #xyzxyz should return false as these are not valid hex digits. Similarly, rgb(c00l, 255, 255) should return false.\nOnly replace matching colors which are at the beginning or end of the line, or are space separated from the text around them. For example, due to the trailing period: I like rgb(1, 2, 3) and rgb(2, 3, 4). becomes I like COLOR and rgb(2, 3, 4).\nReturn the full text with all RGB or hex colors replaced with the word COLOR."
  },
  {
    "objectID": "hw1.html#part-3-text-processing-in-python",
    "href": "hw1.html#part-3-text-processing-in-python",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Part 3: Text Processing in Python",
    "text": "Part 3: Text Processing in Python\nFor this part, you will be playing with a small data set of wine reviews (see the Data section above for download instructions).\nwine.txt is in the format of one review per line, followed by a star rating between 1 and 5 (except for 3 reviews, where the review decided to go rogue and give 6 stars. Pft.) The text of the review and the star rating are separated by a single tab character. There is also a file called stopwords.txt, which you will use for question 3.6.\nwine.txt is also a little peculiar in its format. The encoding of the text file is Latin1 / ISO-8859-1 and depending on the OS of your machine, the default encoding used when running open() may be this encoding or it could be utf-8 (the default encoding on Linux for example). To ensure compatibility specify the encoding when you read in text files.\nIn the wine_text_processing function in hw1_skeleton.py, write code that answers each of the following questions and prints the answer to standard output, followed by a newline. If you get this output it’s very likely your code works correctly! For questions where there are ties, please break the tie alphabetically (e.g. apple would come before banana). We highly recommend looking into the functions available in the Python string module.\nYou will need to write your code in the wine_text_processing function in the hw1_skeleton.py file to answer the following questions. Please note that you need to print out the answers to each of the following questions, like below:\nQuestion 3.1 outputs: `your answer`.\n \nQuestion 3.2 outputs: `your answer`.\n \nQuestion 3.3 outputs: `your answer`.\n...\nYou can choose how you split the text into words (tokenize) or otherwise identify the words in the following questions. It is recommended to use a tokenization tool. Any packages may be imported to aid this.\n3.1. What is the distribution of star ratings? Specifically, this is the counts of reviews per each star value (1 star, 2 star, etc).\n3.2. What are the 10 most common words used across all of the reviews, and how many times is each used? Don’t include stars in the review, but it is okay to include other punctuation or not (your choice).\n3.3. How many times does the word a appear?\n3.4. How many times does the word fruit appear?\n3.5. How many times does the word mineral appear?\n3.6. Common words (like a) are not as interesting as uncommon words (like mineral). In natural language processing, we call these common words stop words and often remove them before we process text. stopwords.txt gives you a list of some very common words. Remove these stopwords from your reviews. Also, try converting all the words to lowercase (since we probably don’t want to count fruit and Fruit as two different words). Now what are the 10 most common words across all of the reviews, and how many times is each used?\n3.7. You should continue to use the preprocessed reviews for the following questions (lowercased, no stopwords). What are the 10 most used words among the 5-star reviews, and how many times is each used?\n3.8. What are the 10 most used words among the 1-star reviews, and how many times is each used?\n3.9. Gather two sets of reviews: 1) Those that use the word red and 2) those that use the word white. What are the 10 most frequent words in the red reviews which do not appear in the white reviews?\n3.10. What are the 10 most frequent words in the white reviews which do not appear in the red reviews?"
  },
  {
    "objectID": "hw1.html#deliverables",
    "href": "hw1.html#deliverables",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Deliverables",
    "text": "Deliverables\n\nYour output CSV from Part 1, named spanish_test.csv\nA modified hw1_skeleton.py file that contains your solutions.\nA README.txt file explaining\n\nhow to run your code\nwhat version of Python you used\nany additional resources, references, or web pages you’ve consulted\nany person with whom you’ve discussed the assignment and describe the nature of your discussions\nany generative AI tool used, and how it was used\nany unresolved issues or problems\n\nAn environment.yml or requirements.txt file listing all Python packages and their versions in your environment (or on your system if you did not use a virtual environment). This may be created using conda env export &gt; environment.yml if using Anaconda, or pip freeze &gt; requirements.txt if using pip and venv.\n\nPlease submit this material on Canvas as individual files. If you used Jupyter Notebook to complete the assignment, please download it as a .py script."
  },
  {
    "objectID": "hw1.html#grading",
    "href": "hw1.html#grading",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Grading",
    "text": "Grading\nWe will be running your code on a different input file to test its performance.  This assignment is worth 60 points."
  },
  {
    "objectID": "hw1.html#acknowledgments",
    "href": "hw1.html#acknowledgments",
    "title": "Homework 1: Text and string processing in Python",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThis assignment is adapted from Prof. Mark Yatskar and Prof. Lorraine Li."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "",
    "text": "School of Computing and Information, University of Pittsburgh\nSpring 2026"
  },
  {
    "objectID": "index.html#participation-grade",
    "href": "index.html#participation-grade",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "Participation grade",
    "text": "Participation grade\nIn-class, collaborative activities are better learning experiences when students come to class and participate. To encourage participation, there is a participation grade worth 10% of the total course grade. The majority of that grade comes from attendance, which will be taken via Top Hat on randomly selected class sessions. The rest of the grade will be assigned based on whether a student asked questions in class or otherwise (such as during office hours), or partipated in in-class activites. If you did any of this basic engagement, full credit will be awarded."
  },
  {
    "objectID": "index.html#grading-scale",
    "href": "index.html#grading-scale",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "Grading scale",
    "text": "Grading scale\n\n\n\nRange\nLetter grade\n\n\n\n\n92.5 – 100%\nA\n\n\n90.0 – &lt;92.5%\nA-\n\n\n87.5 – &lt;90.0%\nB+\n\n\n82.5 – &lt;87.5%\nB\n\n\n80.0 – &lt;82.5%\nB-\n\n\n77.5 – &lt;80.0%\nC+\n\n\n72.5 – &lt;77.5%\nC\n\n\n70.0 – &lt;72.5%\nC-\n\n\n67.5 – &lt;70.0%\nD+\n\n\n62.5 – &lt;67.5%\nD\n\n\n60.0 – &lt;62.5%\nD-\n\n\n&lt; 60%\nF\n\n\n\nFeel free to contact the instructor or schedule an office hours appointment to talk about any issues you might have with your grade."
  },
  {
    "objectID": "index.html#late-work-policy",
    "href": "index.html#late-work-policy",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "Late work policy",
    "text": "Late work policy\nStudents are granted 5 total late days across all homework assignments and quizzes without penalty. After those five late days, you will be penalized 10% for each day that your submission is late up to a maximum of 40%. Group project work will be penalized 10% for each day late up to a maximum of 40%. No late work will be accepted for the project report."
  },
  {
    "objectID": "index.html#assignment-resubmission-policy",
    "href": "index.html#assignment-resubmission-policy",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "Assignment resubmission policy",
    "text": "Assignment resubmission policy\nIf you are unsatisfied with your grade on an assignment and wish to resubmit work, talk with the instructor. Resubmissions are handled case by case, but are generally accepted in cases where parts of the assignment are missing (sections of the rubric are 0). Updated or added text in resubmitted reports must be highlighted in yellow. Resubmissions are subject to an automatic 10% deduction and must be submitted by 11:59pm on the last day of class. They may not be graded until the end of the term. Only 1 resubmission per homework assignment will be accepted."
  },
  {
    "objectID": "index.html#academic-integrity-policy",
    "href": "index.html#academic-integrity-policy",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "Academic integrity policy",
    "text": "Academic integrity policy\nStudents in this course will be expected to comply with the University of Pittsburgh’s Policy on Academic Integrity. Any student suspected of violating this obligation for any reason during the semester will be required to participate in the procedural process, initiated at the instructor level, as outlined in the University Guidelines on Academic Integrity. To learn more about Academic Integrity, visit the Academic Integrity Guide for an overview of the topic. For hands-on practice, complete the Academic Integrity Modules.\nFor any assignment where the academic integrity policy has been violated, students will be assigned a 0 (or a failing grade, depending on the extent).\n\nGenerative AI policy\nYou are allowed to use generative AI programs (ChatGPT, etc.) as a student in this course in limited circumstances. Since much of this course is about developing such tools in NLP, using currently available tools can expose you to the current capabilities and limitations of such systems.\nHowever, your ethical responsibilities as a student remain the same. You must follow the University of Pittsburgh’s Policy on Academic Integrity. Here are some principles to keep in mind that can help you determine whether or not a specific use of generative AI is acceptable in this course (for all forms of generation: writing, code, images or other forms). Please ask the instructor if you are not sure about a specific use. You will not be blamed or retaliated against for asking.\n\nUse as an aid, not for a finished product. LLMs could be used in this course to generate ideas, draft bibliographies, study guides, or for revising existing writing. Use for drafting entire homework or project reports is not acceptable, even if students revise this draft, since being able to communicate NLP procedures and research is a learning objective. Also keep in mind that language models have no notion of reality and will hallucinate facts and citations.\nAllowed code generation varies between homework assignments and the final project. The learning objectives of homework assignments in this class are to be able to implement NLP systems to address specific tasks. As such, code generation is allowed for small pieces of code in homework assignments, but not for the code used for answering an entire question. Students must understand what each line of code in their submitted homework assignments is doing. The open-ended course project, in contrast, focuses more on skills of designing NLP systems for new tasks and datasets. Larger blocks of generated code are allowed in the course project.\nCite its use. The University of Pittsburgh’s academic integrity policy applies to all uncited or improperly cited use of content, whether that work is created by human beings alone or in collaboration with a generative AI. If you use a generative AI tool to develop content for an assignment, you are required to cite the tool’s contribution to your work. In practice, cutting and pasting content from any source without citation is plagiarism. Likewise, paraphrasing content from a generative AI without citation is plagiarism. Similarly, using any generative AI tool without appropriate acknowledgement will be treated as plagiarism. See the APA guidelines on how to cite ChatGPT. Citing your use of LLMs will also inform teaching staff on how such tools are being used in education for developing better future policies.\nYou are responsible for the work you turn in. As we will discuss in this course, LLMs and other generative AI systems can and do generate biased, socially problematic language and assert unfounded claims. Ultimately the text you submit will be treated as reflecting your own work, and you are responsible for it.\n\nAdapted from faculty in the Carnegie Mellon University Heinz College of Information Systems and Public Policy, with guidance from the Carnegie Mellon University Eberly Center for Teaching Excellence."
  },
  {
    "objectID": "index.html#disability-rights",
    "href": "index.html#disability-rights",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "Disability rights",
    "text": "Disability rights\nThe teaching staff of this course view disabilities as deficits not in disabled people but in the institutions and societies that are structured to disadvantage disabled people. If you have a disability (visible or invisible), please let us know as soon as possible. You don’t need to tell us the nature of the disability. You are encouraged to work with Disability Resources and Services (DRS), 140 William Pitt Union, (412) 648-7890, drsrecep@pitt.edu, (412) 228-5347 for P3 ASL users, as early as possible in the term. DRS will work with you to determine reasonable accommodations for this course. This might include lecture materials that are usable by people with visual disabilities, sign language interpretation, captioning, flexible due dates, etc.\nAdapted from policies by David Mortensen and Lori Levin at Carnegie Mellon University."
  },
  {
    "objectID": "index.html#religious-observances",
    "href": "index.html#religious-observances",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "Religious Observances",
    "text": "Religious Observances\nThe observance of religious holidays (activities observed by a religious group of which a student is a member) and cultural practices are an important reflection of diversity. As your instructor, I am committed to providing equivalent educational opportunities to students of all belief systems. At the beginning of the semester, you should review the course requirements to identify foreseeable conflicts with assignments or other required attendance. Please contact me as early as possible to allow time for us to discuss and make fair and reasonable adjustments to the schedule and/or tasks."
  },
  {
    "objectID": "index.html#statement-on-scholarly-discourse",
    "href": "index.html#statement-on-scholarly-discourse",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "Statement on scholarly discourse",
    "text": "Statement on scholarly discourse\nIn this course we will be discussing some complex issues on which all of us have strong feelings and, in many cases, unfounded attitudes. It is essential that we approach this endeavor with our minds open to evidence that may conflict with our presuppositions. Moreover, it is vital that we treat each other’s opinions and comments with courtesy even when they diverge and conflict with our own. We must avoid personal attacks and the use of ad hominem arguments to invalidate each other’s positions. Instead, we must develop a culture of civil argumentation, wherein all positions have the right to be defended and argued against in intellectually reasoned ways.\nAdapted from a California State University course: Race, Racism and Critical Thinking."
  },
  {
    "objectID": "index.html#student-wellness",
    "href": "index.html#student-wellness",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "Student wellness",
    "text": "Student wellness\nCollege can be an exciting and challenging time for students. Taking time to maintain your well-being and seek appropriate support can help you achieve your goals and lead a fulfilling life. It can be helpful to remember that we all benefit from assistance and guidance at times, and there are many resources available to support your well-being while you are at Pitt. You are encouraged to visit Thrive@Pitt to learn more about well-being and the many campus resources available to help you thrive.\nIf you or anyone you know experiences overwhelming academic stress, persistent difficult feelings and/or challenging life events, you are strongly encouraged to seek support. In addition to reaching out to friends and loved ones, consider connecting with a faculty member you trust for assistance connecting to helpful resources.\nThe University Counseling Center is also here for you. You can call 412-648-7930 at any time to connect with a clinician. If you or someone you know is feeling suicidal, please call the University Counseling Center at any time at 412-648-7930. You can also contact Resolve Crisis Network at 888-796-8226."
  },
  {
    "objectID": "index.html#equity-and-inclusion",
    "href": "index.html#equity-and-inclusion",
    "title": "CS 1671 / CS 2071 / ISSP 2071Human Language Technologies",
    "section": "Equity and inclusion",
    "text": "Equity and inclusion\nThe University of Pittsburgh does not tolerate any form of discrimination, harassment, or retaliation based on disability, race, color, religion, national origin, ancestry, genetic information, marital status, familial status, sex, age, sexual orientation, veteran status or gender identity or other factors as stated in the University’s Title IX policy. The University is committed to taking prompt action to end a hostile environment that interferes with the University’s mission. For more information about policies, procedures, and practices, visit the Civil Rights & Title IX Compliance web page.\nI ask that everyone in the class strive to help ensure that other members of this class can learn in a supportive and respectful environment. If there are instances of the aforementioned issues, please contact the Title IX Coordinator, by calling 412-648-7860, or emailing titleixcoordinator@pitt.edu. Reports can also be filed online. You may also choose to report this to a faculty/staff member; they are required to communicate this to the University’s Office of Diversity and Inclusion. If you wish to maintain complete confidentiality, you may also contact the University Counseling Center (412-648-7930)."
  }
]